<!doctype html><html lang=en-us><head><link rel=preload href=/lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script type=text/javascript src=https://latest.cactus.chat/cactus.js></script><link rel=stylesheet href=https://latest.cactus.chat/style.css type=text/css><style>body.glightbox-open{overflow-y:scroll!important}</style><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>Operating Inference as Infrastructure: A GenAI Implementation Journal | Zaft Memory Core </title><link rel=canonical href=https://davmig.github.io/posts/genai-inference-platform-implementation/><meta name=description content="Welcome to Zaft Memory Core — a personal archive for my thoughts, ideas, and technical explorations. This platform is where I document my journey, from code snippets and project insights to creative concepts worth revisiting. It’s more than just a collection—it's a reflection of how I think, organize, and approach challenges. Designed to be simple yet effective, Zaft Memory Core keeps everything I need in one place, ready to evolve alongside my skills and interests. Because every idea deserves structure."><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:url" content="https://davmig.github.io/posts/genai-inference-platform-implementation/"><meta property="og:site_name" content="Zaft Memory Core "><meta property="og:title" content="Operating Inference as Infrastructure: A GenAI Implementation Journal"><meta property="og:description" content="Operating Inference as Infrastructure This project started as a side project.
But from the beginning, I made a deliberate choice:
Even as a solo engineer, AI integration would be treated as production infrastructure, not as a feature experiment.
The objective was not to “connect an LLM”.
The objective was to design inference as a first-class platform capability inside the product.
Context: The Typical First Iteration The initial implementation looked like most early GenAI integrations:"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-22T00:00:00+00:00"><meta property="article:modified_time" content="2026-02-22T00:00:00+00:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="GenAI"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Architecture"><meta property="article:tag" content="Infrastructure"><meta name=twitter:card content="summary"><meta name=twitter:title content="Operating Inference as Infrastructure: A GenAI Implementation Journal"><meta name=twitter:description content="Operating Inference as Infrastructure This project started as a side project.
But from the beginning, I made a deliberate choice:
Even as a solo engineer, AI integration would be treated as production infrastructure, not as a feature experiment.
The objective was not to “connect an LLM”.
The objective was to design inference as a first-class platform capability inside the product.
Context: The Typical First Iteration The initial implementation looked like most early GenAI integrations:"><link rel=stylesheet href=https://davmig.github.io/css/styles.c05d68261bf086a9d7713c4f8a6215a3601608e267a816a7ee58f139b3d1aae51222aae2081c8e0c6bd35e1334773b7a16283022f31f92afd93bb37e5e822e66.css integrity="sha512-wF1oJhvwhqnXcTxPimIVo2AWCOJnqBan7ljxObPRquUSIqriCByODGvTXhM0dzt6FigwIvMfkq/ZO7N+XoIuZg=="><link rel=stylesheet href=https://unpkg.com/litelight-js@latest/dist/lite-light.min.css><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://davmig.github.io/images/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=false"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","false")}</script></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Main</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li><li><a href=/posts/>Posts</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://davmig.github.io/posts/genai-implementation-methodology-tcg/ aria-label=Previous><i class="fas fa-chevron-left" aria-hidden=true onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&text=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&is_video=false&description=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal&body=Check out this article: https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&name=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal&description=%3ch1%20id%3d%22operating-inference-as-infrastructure%22%3eOperating%20Inference%20as%20Infrastructure%3c%2fh1%3e%0a%3cp%3eThis%20project%20started%20as%20a%20side%20project.%3c%2fp%3e%0a%3cp%3eBut%20from%20the%20beginning%2c%20I%20made%20a%20deliberate%20choice%3a%3cbr%3e%0aEven%20as%20a%20solo%20engineer%2c%20AI%20integration%20would%20be%20treated%20as%20production%20infrastructure%2c%20not%20as%20a%20feature%20experiment.%3c%2fp%3e%0a%3cp%3eThe%20objective%20was%20not%20to%20%e2%80%9cconnect%20an%20LLM%e2%80%9d.%3c%2fp%3e%0a%3cp%3eThe%20objective%20was%20to%20design%20inference%20as%20a%20first-class%20platform%20capability%20inside%20the%20product.%3c%2fp%3e%0a%3chr%3e%0a%3ch2%20id%3d%22context-the-typical-first-iteration%22%3eContext%3a%20The%20Typical%20First%20Iteration%3c%2fh2%3e%0a%3cp%3eThe%20initial%20implementation%20looked%20like%20most%20early%20GenAI%20integrations%3a%3c%2fp%3e" aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&t=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#context-the-typical-first-iteration>Context: The Typical First Iteration</a></li><li><a href=#architectural-target>Architectural Target</a></li><li><a href=#provider-abstraction>Provider Abstraction</a></li><li><a href=#routing-by-use-case>Routing by Use Case</a></li><li><a href=#security-at-the-inference-boundary>Security at the Inference Boundary</a><ul><li><a href=#authorization>Authorization</a></li><li><a href=#rate-limiting>Rate Limiting</a></li><li><a href=#secret-validation>Secret Validation</a></li><li><a href=#structured-logging>Structured Logging</a></li></ul></li><li><a href=#runtime-governance>Runtime Governance</a></li><li><a href=#explicit-orchestration-with-langgraph>Explicit Orchestration with LangGraph</a></li><li><a href=#before-vs-after>Before vs After</a><ul><li><a href=#before>Before</a></li><li><a href=#after>After</a></li></ul></li><li><a href=#lessons-learned>Lessons Learned</a></li><li><a href=#whats-next>What’s Next</a></li><li><a href=#closing>Closing</a></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">Operating Inference as Infrastructure: A GenAI Implementation Journal</h1><div class=meta><div class=postdate><time datetime="2026-02-22 00:00:00 +0000 UTC" itemprop=datePublished>2026-02-22</time></div><div class=article-read-time><i class="far fa-clock"></i>
4 minute read</div><div class=article-category><i class="fas fa-archive"></i>
<a class=category-link href=/categories/engineering>Engineering</a>
,
<a class=category-link href=/categories/ai>AI</a></div><div class=article-tag><i class="fas fa-tag"></i>
<a class=tag-link href=/tags/ai rel=tag>AI</a>
,
<a class=tag-link href=/tags/genai rel=tag>GenAI</a>
,
<a class=tag-link href=/tags/llm rel=tag>LLM</a>
,
<a class=tag-link href=/tags/architecture rel=tag>Architecture</a>
,
<a class=tag-link href=/tags/infrastructure rel=tag>Infrastructure</a></div></div></header><div class=content itemprop=articleBody><h1 id=operating-inference-as-infrastructure>Operating Inference as Infrastructure</h1><p>This project started as a side project.</p><p>But from the beginning, I made a deliberate choice:<br>Even as a solo engineer, AI integration would be treated as production infrastructure, not as a feature experiment.</p><p>The objective was not to “connect an LLM”.</p><p>The objective was to design inference as a first-class platform capability inside the product.</p><hr><h2 id=context-the-typical-first-iteration>Context: The Typical First Iteration</h2><p>The initial implementation looked like most early GenAI integrations:</p><ul><li>Direct provider SDK calls inside services</li><li>Prompt logic embedded in feature code</li><li>Tactical solutions for admin workflows</li></ul><p>It worked.</p><p>But it introduced structural risks:</p><ol><li>Provider coupling inside business logic</li><li>No centralized policy layer</li><li>Hardcoded routing decisions</li><li>No explicit security boundary</li><li>Multi-step workflows without clear orchestration</li></ol><p>Scaling this approach would eventually require a rewrite.</p><p>So instead of incrementally patching it, I redesigned the inference layer.</p><hr><h2 id=architectural-target>Architectural Target</h2><p>Even as a solo project, I defined strict architectural constraints:</p><ul><li>A single application-level entrypoint: <code>InferenceService</code></li><li>Provider connectors behind a shared contract</li><li>Runtime routing by use case</li><li>Built-in fallback handling</li><li>Authorization enforced at the inference boundary</li><li>Structured logging by default</li><li>Rate limiting per actor</li><li>Explicit workflow orchestration via LangGraph</li><li>Runtime configurability of provider strategy</li></ul><p>AI execution became infrastructure, not utility code.</p><hr><h2 id=provider-abstraction>Provider Abstraction</h2><p>The business layer must not depend on provider SDKs.</p><p>All providers implement the same contract:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#ff79c6>export</span> <span style=color:#ff79c6>type</span> InferenceConnector <span style=color:#ff79c6>=</span> {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  <span style=color:#ff79c6>readonly</span> provider: <span style=color:#8be9fd>InferenceProvider</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>  invoke(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>    request: <span style=color:#8be9fd>InferenceInvokeRequest</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>    context: <span style=color:#8be9fd>InferenceContext</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>  )<span style=color:#ff79c6>:</span> Promise&lt;<span style=color:#ff79c6>InferenceInvokeResponse</span>&gt;
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>  stream<span style=color:#ff79c6>?</span>(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>    request: <span style=color:#8be9fd>InferenceInvokeRequest</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>    context: <span style=color:#8be9fd>InferenceContext</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>  )<span style=color:#ff79c6>:</span> AsyncIterable&lt;<span style=color:#ff79c6>string</span>&gt;
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>  embeddings<span style=color:#ff79c6>?</span>(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>    request: <span style=color:#8be9fd>InferenceEmbeddingsRequest</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>    context: <span style=color:#8be9fd>InferenceContext</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>  )<span style=color:#ff79c6>:</span> Promise&lt;<span style=color:#ff79c6>InferenceEmbeddingsResponse</span>&gt;
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>}
</span></span></code></pre></div><p>Concrete implementations:</p><ul><li><code>MistralInferenceConnector</code></li><li><code>OpenAiInferenceConnector</code></li></ul><p>This guarantees:</p><ul><li>Providers can be swapped without modifying feature code</li><li>Routing and policy logic remain centralized</li><li>Error handling is consistent</li><li>Testing is isolated from provider SDKs</li></ul><p>Even in a side project, architectural isolation matters.</p><hr><h2 id=routing-by-use-case>Routing by Use Case</h2><p>Routing decisions are not hardcoded.</p><p>An <code>InferenceRouter</code> resolves configuration from:</p><ul><li>A Supabase table: <code>inference_provider_config</code></li><li>Environment fallback</li><li>In-memory TTL cache</li></ul><p>Schema:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#ff79c6>create</span> <span style=color:#ff79c6>table</span> <span style=color:#ff79c6>if</span> <span style=color:#ff79c6>not</span> <span style=color:#ff79c6>exists</span> <span style=color:#ff79c6>public</span>.inference_provider_config (
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>  use_case <span style=color:#8be9fd;font-style:italic>text</span> <span style=color:#ff79c6>primary</span> <span style=color:#ff79c6>key</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>  primary_provider <span style=color:#8be9fd;font-style:italic>text</span> <span style=color:#ff79c6>not</span> <span style=color:#ff79c6>null</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span>  model <span style=color:#8be9fd;font-style:italic>text</span> <span style=color:#ff79c6>not</span> <span style=color:#ff79c6>null</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>  fallback_provider <span style=color:#8be9fd;font-style:italic>text</span> <span style=color:#ff79c6>null</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span>  enabled <span style=color:#8be9fd;font-style:italic>boolean</span> <span style=color:#ff79c6>not</span> <span style=color:#ff79c6>null</span> <span style=color:#ff79c6>default</span> <span style=color:#ff79c6>true</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7</span><span>  updated_at timestamptz <span style=color:#ff79c6>not</span> <span style=color:#ff79c6>null</span> <span style=color:#ff79c6>default</span> now()
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8</span><span>);
</span></span></code></pre></div><p>Routing behavior:</p><ul><li>Resolve use case configuration</li><li>Call primary provider</li><li>Fallback on transient errors (timeout, rate limit, provider error)</li><li>Fail fast on non-recoverable errors</li></ul><p>Provider strategy becomes an operational configuration decision, not a deployment event.</p><hr><h2 id=security-at-the-inference-boundary>Security at the Inference Boundary</h2><p>Inference is treated as a security boundary.</p><h3 id=authorization>Authorization</h3><p>Each call validates:</p><ul><li><code>useCase</code></li><li><code>actorId</code></li><li><code>actorRole</code></li></ul><p>Example policies:</p><ul><li><code>admin</code> → role <code>admin</code>, actor required</li><li><code>user_chat</code> → roles <code>user | admin</code>, actor required</li></ul><p>No matching policy means no inference call.</p><hr><h3 id=rate-limiting>Rate Limiting</h3><p>Quotas apply per <code>(useCase, actorId)</code>:</p><ul><li>60 requests</li><li>60-second window</li></ul><p>Exceeding quota returns explicit 429 semantics.</p><hr><h3 id=secret-validation>Secret Validation</h3><p>API keys are validated at startup:</p><ul><li><code>MISTRAL_API_KEY</code></li><li><code>OPENAI_API_KEY</code></li></ul><p>Misconfiguration fails fast.</p><hr><h3 id=structured-logging>Structured Logging</h3><p>Each inference call logs:</p><ul><li><code>traceId</code></li><li><code>useCase</code></li><li><code>actorId</code> / role</li><li>provider and model</li><li>latency</li><li>token usage</li><li>status or error code</li></ul><p>Raw prompts and responses are not logged by default.</p><p>Observability is built-in, not retrofitted.</p><hr><h2 id=runtime-governance>Runtime Governance</h2><p>An admin interface allows:</p><ul><li>Primary provider selection</li><li>Model selection</li><li>Fallback configuration</li><li>Enabling or disabling inference per use case</li></ul><p>Configuration changes are audited and persisted.</p><p>Even as a solo project, inference strategy remains observable and controlled.</p><hr><h2 id=explicit-orchestration-with-langgraph>Explicit Orchestration with LangGraph</h2><p>A production admin workflow was migrated to LangGraph:</p><p><code>runExtractionWithPrompt</code></p><p>Nodes:</p><ul><li><code>load_context</code></li><li><code>invoke_model</code></li><li><code>parse_output</code></li><li><code>persist_result</code></li></ul><p>Example:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-typescript data-lang=typescript><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#ff79c6>const</span> adminExtractionGraph <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>new</span> StateGraph(ExtractionGraphState)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>  .addNode(<span style=color:#f1fa8c>&#39;load_context&#39;</span>, <span style=color:#ff79c6>async</span> (state) <span style=color:#ff79c6>=&gt;</span> {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>    <span style=color:#6272a4>// context preparation
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span><span style=color:#6272a4></span>  })
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>  .addNode(<span style=color:#f1fa8c>&#39;invoke_model&#39;</span>, <span style=color:#ff79c6>async</span> (state) <span style=color:#ff79c6>=&gt;</span> {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>    <span style=color:#6272a4>// inference call
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span><span style=color:#6272a4></span>  })
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>  .addNode(<span style=color:#f1fa8c>&#39;parse_output&#39;</span>, <span style=color:#ff79c6>async</span> (state) <span style=color:#ff79c6>=&gt;</span> {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>    <span style=color:#6272a4>// parsing and resolution
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span><span style=color:#6272a4></span>  })
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>  .addNode(<span style=color:#f1fa8c>&#39;persist_result&#39;</span>, <span style=color:#ff79c6>async</span> (state) <span style=color:#ff79c6>=&gt;</span> {
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>    <span style=color:#6272a4>// audit and persistence
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span><span style=color:#6272a4></span>  })
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>  .addEdge(START, <span style=color:#f1fa8c>&#39;load_context&#39;</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>  .addEdge(<span style=color:#f1fa8c>&#39;load_context&#39;</span>, <span style=color:#f1fa8c>&#39;invoke_model&#39;</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>  .addEdge(<span style=color:#f1fa8c>&#39;invoke_model&#39;</span>, <span style=color:#f1fa8c>&#39;parse_output&#39;</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span>  .addEdge(<span style=color:#f1fa8c>&#39;parse_output&#39;</span>, <span style=color:#f1fa8c>&#39;persist_result&#39;</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>  .addEdge(<span style=color:#f1fa8c>&#39;persist_result&#39;</span>, END)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>  .compile();
</span></span></code></pre></div><p>Even inside graph nodes, inference is executed through <code>InferenceService</code>.</p><p>Orchestration never bypasses platform controls.</p><hr><h2 id=before-vs-after>Before vs After</h2><h3 id=before>Before</h3><ul><li>Direct SDK calls</li><li>Provider logic embedded in features</li><li>Inconsistent error handling</li><li>No unified governance surface</li><li>Implicit workflow logic</li></ul><h3 id=after>After</h3><ul><li>Centralized inference service</li><li>Provider abstraction</li><li>Runtime routing</li><li>Security at the boundary</li><li>Rate limiting</li><li>Structured observability</li><li>Explicit orchestration</li><li>Configurable strategy</li></ul><hr><h2 id=lessons-learned>Lessons Learned</h2><ol><li>Governance is easier to design early than to retrofit.</li><li>Even a side project benefits from production discipline.</li><li>Security boundaries must explicitly include inference.</li><li>Routing by use case enables controlled experimentation.</li><li>Clear documentation strengthens architectural longevity.</li></ol><hr><h2 id=whats-next>What’s Next</h2><p>The next step is a user chatbot with Pinecone-backed RAG, built on the same primitives:</p><ul><li><code>invokeByUseCase</code> for generation</li><li><code>embeddings</code> for ingestion</li><li>Identical routing and policy enforcement</li><li>Graph-based orchestration for retrieval and generation</li></ul><p>The objective is additive capability, not architectural reset.</p><hr><h2 id=closing>Closing</h2><p>This system is built by a single engineer.</p><p>But it follows platform-level design principles:</p><ul><li>Isolation</li><li>Governance</li><li>Observability</li><li>Security</li><li>Configurability</li></ul><p>Integrating AI is easy.</p><p>Operating inference responsibly is engineering.</p></div></article><div class=blog-post-comments><div id=cactus-comments-thread><script>initComments({node:document.getElementById("cactus-comments-thread"),defaultHomeserverUrl:"https://matrix.cactus.chat:8448",serverName:"cactus.chat",siteName:"your_cactus_comments_sitename",commentSectionId:"/posts/genai-inference-platform-implementation/"})</script></div></div><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Main</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li><li><a href=/posts/>Posts</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#context-the-typical-first-iteration>Context: The Typical First Iteration</a></li><li><a href=#architectural-target>Architectural Target</a></li><li><a href=#provider-abstraction>Provider Abstraction</a></li><li><a href=#routing-by-use-case>Routing by Use Case</a></li><li><a href=#security-at-the-inference-boundary>Security at the Inference Boundary</a><ul><li><a href=#authorization>Authorization</a></li><li><a href=#rate-limiting>Rate Limiting</a></li><li><a href=#secret-validation>Secret Validation</a></li><li><a href=#structured-logging>Structured Logging</a></li></ul></li><li><a href=#runtime-governance>Runtime Governance</a></li><li><a href=#explicit-orchestration-with-langgraph>Explicit Orchestration with LangGraph</a></li><li><a href=#before-vs-after>Before vs After</a><ul><li><a href=#before>Before</a></li><li><a href=#after>After</a></li></ul></li><li><a href=#lessons-learned>Lessons Learned</a></li><li><a href=#whats-next>What’s Next</a></li><li><a href=#closing>Closing</a></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&text=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&is_video=false&description=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal&body=Check out this article: https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&title=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&name=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal&description=%3ch1%20id%3d%22operating-inference-as-infrastructure%22%3eOperating%20Inference%20as%20Infrastructure%3c%2fh1%3e%0a%3cp%3eThis%20project%20started%20as%20a%20side%20project.%3c%2fp%3e%0a%3cp%3eBut%20from%20the%20beginning%2c%20I%20made%20a%20deliberate%20choice%3a%3cbr%3e%0aEven%20as%20a%20solo%20engineer%2c%20AI%20integration%20would%20be%20treated%20as%20production%20infrastructure%2c%20not%20as%20a%20feature%20experiment.%3c%2fp%3e%0a%3cp%3eThe%20objective%20was%20not%20to%20%e2%80%9cconnect%20an%20LLM%e2%80%9d.%3c%2fp%3e%0a%3cp%3eThe%20objective%20was%20to%20design%20inference%20as%20a%20first-class%20platform%20capability%20inside%20the%20product.%3c%2fp%3e%0a%3chr%3e%0a%3ch2%20id%3d%22context-the-typical-first-iteration%22%3eContext%3a%20The%20Typical%20First%20Iteration%3c%2fh2%3e%0a%3cp%3eThe%20initial%20implementation%20looked%20like%20most%20early%20GenAI%20integrations%3a%3c%2fp%3e" aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fdavmig.github.io%2fposts%2fgenai-inference-platform-implementation%2f&t=Operating%20Inference%20as%20Infrastructure%3a%20A%20GenAI%20Implementation%20Journal" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><script type=module>
    import { init } from 'https://unpkg.com/litelight-js@latest/dist/lite-light.min.js';
    document.addEventListener('DOMContentLoaded', () => {
      init();
    });
  </script><div class=footer-left>Copyright &copy; 2026 Zaft Memory Core</div><div class=footer-right><nav><ul><li><a href=/>Main</a></li><li><a href=/posts>Writings</a></li><li><a href=/tags>Tags</a></li><li><a href=/about>About</a></li><li><a href=/posts/>Posts</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script><script src=/js/main.js></script><script src=/js/code-copy.js></script></html>